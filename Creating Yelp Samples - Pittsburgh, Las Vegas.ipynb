{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing things, JSON reader function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading business.json\n",
      "Creating business_sample.json\n",
      "Getting business_ids\n",
      "Reading review.json\n",
      "Creating review_sample.json line by line\n",
      "Getting user_ids\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n# USER.JSON\\nuser_data = []\\nwith open(os.path.dirname(__file__) + user_file) as f:\\n    for line in f:\\n        newline = ast.literal_eval(line)  # read the line (str) as a dict\\n        if newline['user_id'] in user_ids:\\n            user_data.append(json.loads(line))\\nuser_df = pd.DataFrame.from_dict(user_data)\\nprint 'Creating user_sample.json'\\nwith open('user_sample.json', 'w') as f:\\n    user_df.to_json(f, orient='records', lines=True)\\n\\n# TIP.JSON\\ntip_data = []\\nprint 'Reading tip.json'\\nwith open(os.path.dirname(__file__) + tip_file) as f:\\n    for line in f:\\n        newline = ast.literal_eval(line)\\n        if newline['business_id'] in business_ids:\\n            tip_data.append(json.loads(line))\\ntip_df = pd.DataFrame.from_dict(tip_data)\\nprint 'Creating tip_sample.json'\\nwith open('tip_sample.json', 'w') as f:\\n    tip_df.to_json(f, orient='records', lines=True)\\n\\n# CHECKIN.JSON\\ncheckin_data = []\\nprint 'Reading checkin.json'\\nwith open(os.path.dirname(__file__) + checkin_file) as f:\\n    for line in f:\\n        newline = ast.literal_eval(line)\\n        if newline['business_id'] in business_ids:\\n            checkin_data.append(json.loads(line))\\ncheckin_df = pd.DataFrame.from_dict(checkin_data)\\nprint 'Creating checkin_sample.json'\\nwith open('checkin_sample.json', 'w') as f:\\n    checkin_df.to_json(f, orient='records', lines=True)\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, string\n",
    "import json\n",
    "import os\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code copied from https://www.kaggle.com/vksbhandary/exploring-yelp-reviews-dataset\n",
    "def init_ds(json):\n",
    "    ds= {}\n",
    "    keys = json.keys()\n",
    "    for k in keys:\n",
    "        ds[k]= []\n",
    "    return ds, keys\n",
    "\n",
    "def read_json(file):\n",
    "    dataset = {}\n",
    "    keys = []\n",
    "    with open(file) as file_lines:\n",
    "        for count, line in enumerate(file_lines):\n",
    "            data = json.loads(line.strip())\n",
    "            if count ==0:\n",
    "                dataset, keys = init_ds(data)\n",
    "            for k in keys:\n",
    "                dataset[k].append(data[k])\n",
    "                \n",
    "        return pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Yelp Business Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "businesses = read_json('yelp_academic_dataset_business.json')\n",
    "print(businesses.columns)\n",
    "print(businesses.shape)\n",
    "\n",
    "# Filter for places that are open, is_open = 1\n",
    "businesses = businesses[businesses.is_open == 1]\n",
    "# Filter out places that don't have any category\n",
    "businesses = businesses.dropna(subset = ['categories'])\n",
    "print(businesses.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering for PGH/LV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for Pittsburgh\n",
    "# Typos to consider: Pittsburg, Pittsburch, Pitsburgh, Pittsbuirgh, PITTSBURGH AP\n",
    "pitt_string = (businesses.city.str.strip().str.lower() == 'pittsburgh') | \\\n",
    "              (businesses.city.str.strip().str.lower() == 'pittsburg') | \\\n",
    "              (businesses.city.str.strip().str.lower() == 'pittsburch') | \\\n",
    "              (businesses.city.str.strip().str.lower() == 'pitsburgh') | \\\n",
    "              (businesses.city.str.strip().str.lower() == 'pittsbuirgh') | \\\n",
    "              (businesses.city.str.strip().str.lower() == 'pittsburgh ap') \n",
    "pa_string = businesses.state == 'PA'\n",
    "pittsburgh = businesses[(pitt_string) & (pa_string)]\n",
    "\n",
    "# Convert all to Pittsburgh to make it cleaner\n",
    "pittsburgh.loc[:, \"city\"] = np.repeat('Pittsburgh', len(pittsburgh))\n",
    "pittsburgh.city.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for Las Vegas\n",
    "# Typos to consider: Las Vegas Ap; Las Vegas East; Las Vegas Nv; Las Vegas Nevada; Las Vegas, Nevada; Las Vegas, NV; Las Vegass; Las Vegas,\n",
    "lv_string = (businesses.city.str.strip().str.lower() == 'las vegas') | \\\n",
    "            (businesses.city.str.strip().str.lower() == 'las vegas ap') | \\\n",
    "            (businesses.city.str.strip().str.lower() == 'las vegas east') | \\\n",
    "            (businesses.city.str.strip().str.lower() == 'las vegas nv') | \\\n",
    "            (businesses.city.str.strip().str.lower() == 'las vegas nevada') | \\\n",
    "            (businesses.city.str.strip().str.lower() == 'las vegas,') | \\\n",
    "            (businesses.city.str.strip().str.lower() == 'las vegas, nevada') | \\\n",
    "            (businesses.city.str.strip().str.lower() == 'las vegas, nv') | \\\n",
    "            (businesses.city.str.strip().str.lower() == 'las vegass')\n",
    "nv_string = businesses.state == 'NV'\n",
    "las_vegas = businesses[(lv_string) & (nv_string)]\n",
    "\n",
    "# Convert all to Pittsburgh to make it cleaner\n",
    "las_vegas.city = np.repeat('Las Vegas', len(las_vegas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pittsburgh_sample.json', 'w') as f:\n",
    "    pittsburgh.to_json(f, orient='records', lines=True)\n",
    "    \n",
    "with open('las_vegas_sample.json', 'w') as f:\n",
    "    las_vegas.to_json(f, orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding top 100 + their business IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_100_pgh = pittsburgh.sort_values(by = 'review_count', ascending = False)[:100]\n",
    "top_100_lv = las_vegas.sort_values(by = 'review_count', ascending = False)[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitt_100_ids = pd.Series(top_100_pgh['business_id'].index.values, index=top_100_pgh['business_id']).to_dict()\n",
    "lv_100_ids = pd.Series(top_100_lv['business_id'].index.values, index=top_100_lv['business_id']).to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reviews data - top 100 busineses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_data = []\n",
    "print('Reading review.json')\n",
    "with open('yelp_academic_dataset_review.json') as f:\n",
    "    for line in f:\n",
    "        newline = ast.literal_eval(line)  # read the line (str) as a dict\n",
    "        if newline['business_id'] in pitt_100_ids:\n",
    "            review_data.append(json.loads(line))\n",
    "print('converting to data frame')\n",
    "review_df = pd.DataFrame.from_dict(review_data)\n",
    "# get list of business id's from business.json and only keep reviews of those businesses\n",
    "# would normally write it with to_json but it's too big to fit in memory, so write it line by line\n",
    "print('Creating review_sample.json line by line')\n",
    "with open('pitt_reviews_sample.json', 'w') as f:\n",
    "    review_df.to_json(f, orient='records', lines=True)\n",
    "    \n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_data = []\n",
    "print('Reading review.json')\n",
    "with open('yelp_academic_dataset_review.json') as f:\n",
    "    for line in f:\n",
    "        newline = ast.literal_eval(line)  # read the line (str) as a dict\n",
    "        if newline['business_id'] in lv_100_ids:\n",
    "            review_data.append(json.loads(line))\n",
    "print('converting to data frame')\n",
    "review_df = pd.DataFrame.from_dict(review_data)\n",
    "# get list of business id's from business.json and only keep reviews of those businesses\n",
    "# would normally write it with to_json but it's too big to fit in memory, so write it line by line\n",
    "print('Creating review_sample.json line by line')\n",
    "with open('lv_reviews_sample.json', 'w') as f:\n",
    "    review_df.to_json(f, orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tips data - top 100 businesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tip_data = []\n",
    "print('Reading tip.json')\n",
    "with open('yelp_academic_dataset_tip.json') as f:\n",
    "    for line in f:\n",
    "        newline = ast.literal_eval(line)\n",
    "        if newline['business_id'] in pitt_100_ids:\n",
    "            tip_data.append(json.loads(line))\n",
    "print('Converting to DF')\n",
    "tip_df = pd.DataFrame.from_dict(tip_data)\n",
    "print('Creating json file')\n",
    "with open('tip_pittsburgh.json', 'w') as f:\n",
    "    tip_df.to_json(f, orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tip_data = []\n",
    "print('Reading tip.json')\n",
    "with open('yelp_academic_dataset_tip.json') as f:\n",
    "    for line in f:\n",
    "        newline = ast.literal_eval(line)\n",
    "        if newline['business_id'] in lv_100_ids:\n",
    "            tip_data.append(json.loads(line))\n",
    "print('Converting to DF')\n",
    "tip_df = pd.DataFrame.from_dict(tip_data)\n",
    "print('Creating json file')\n",
    "with open('tip_lv.json', 'w') as f:\n",
    "    tip_df.to_json(f, orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check-ins data - top 100 businesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkin_data = []\n",
    "print('Reading checkin.json')\n",
    "with open('yelp_academic_dataset_checkin.json') as f:\n",
    "    for line in f:\n",
    "        newline = ast.literal_eval(line)\n",
    "        if newline['business_id'] in pitt_100_ids:\n",
    "            checkin_data.append(json.loads(line))\n",
    "checkin_df = pd.DataFrame.from_dict(checkin_data)\n",
    "print('Creating checkin_sample.json')\n",
    "with open('pitt_checkin.json', 'w') as f:\n",
    "    checkin_df.to_json(f, orient='records', lines=True)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkin_data = []\n",
    "print('Reading checkin.json')\n",
    "with open('yelp_academic_dataset_checkin.json') as f:\n",
    "    for line in f:\n",
    "        newline = ast.literal_eval(line)\n",
    "        if newline['business_id'] in lv_100_ids:\n",
    "            checkin_data.append(json.loads(line))\n",
    "checkin_df = pd.DataFrame.from_dict(checkin_data)\n",
    "print('Creating checkin_sample.json')\n",
    "with open('lv_checkin.json', 'w') as f:\n",
    "    checkin_df.to_json(f, orient='records', lines=True)\n",
    "print('Done!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
